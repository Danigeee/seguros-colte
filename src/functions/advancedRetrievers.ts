import { SupabaseVectorStore } from '@langchain/community/vectorstores/supabase';
import { OpenAIEmbeddings } from '@langchain/openai';
import { createClient } from '@supabase/supabase-js';
import { ChatOpenAI } from "@langchain/openai";
import { HumanMessage, SystemMessage } from "@langchain/core/messages";
import dotenv from 'dotenv';

//! Comentario importante: Esta funci√≥n es una versi√≥n mejorada de searchBienestarDocuments, pero en este momento no se est√° usando en ning√∫n agente. Se planea integrarla en el futuro para mejorar la precisi√≥n de las respuestas mediante re-ranking con LLM.

dotenv.config();

const embeddings = new OpenAIEmbeddings({ openAIApiKey: process.env.OPENAI_API_KEY });
const supabaseUrl = process.env.SUPABASE_URL!;
const supabaseApiKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

// Usamos un modelo r√°pido y barato para el re-ranking
const rerankLLM = new ChatOpenAI({
    temperature: 0,
    model: "gpt-4o-mini",
    apiKey: process.env.OPENAI_API_KEY,
});

interface SearchResult {
    pageContent: string;
    metadata: any;
    score?: number;
}

/**
 * Realiza una b√∫squeda vectorial y luego refina los resultados usando un LLM (Re-ranking).
 * Esto mejora dr√°sticamente la precisi√≥n al eliminar chunks irrelevantes.
 */
export const smartSearchBienestar = async (query: string): Promise<string> => {
    try {
        const client = createClient(supabaseUrl, supabaseApiKey);

        // Usamos la misma tabla y funci√≥n que ya tienes configurada y funcionando
        const vectorStore = new SupabaseVectorStore(embeddings, {
            client,
            tableName: 'documents_bienestar_final',
            queryName: 'match_documents_bienestar_final'
        });

        console.log(`üîç Smart Search: Buscando vectores para "${query}"...`);
        
        // 1. Recuperaci√≥n Amplia (Broad Retrieval)
        // Traemos 15 candidatos para no perder nada potencial
        const results = await vectorStore.similaritySearchWithScore(query, 15);

        if (results.length === 0) {
            console.log("‚ö†Ô∏è No se encontraron vectores.");
            return "";
        }

        // 2. Filtrado por Umbral B√°sico (Thresholding)
        // Eliminamos coincidencias muy pobres.
        const candidates = results.filter(([doc, score]) => score > 0.65).map(([doc, score]) => ({
            pageContent: doc.pageContent,
            metadata: doc.metadata,
            score
        }));

        console.log(`üìä Candidatos iniciales: ${results.length} -> Filtrados por score: ${candidates.length}`);

        if (candidates.length === 0) return "";

        // 3. Re-ranking / Filtrado Sem√°ntico con LLM
        const relevantContent = await rerankChunksWithLLM(query, candidates);

        return relevantContent;
        
    } catch (error) {
        console.error('‚ùå Error en smartSearchBienestar:', error);
        return ""; 
    }
}

async function rerankChunksWithLLM(query: string, docs: SearchResult[]): Promise<string> {
    // Preparamos los chunks numerados para el LLM
    const docsText = docs.map((d, i) => `[FRAGMENTO ${i + 1}]\n${d.pageContent}`).join('\n\n');

    const systemPrompt = `Eres un experto analista de documentos de seguros. Tu trabajo es filtrar informaci√≥n irrelevante.
Tienes una lista de fragmentos de texto recuperados de una base de datos y una pregunta del usuario.
Debes evaluar CADA fragmento y decidir si contiene informaci√≥n √∫til para responder la pregunta.

CRITERIOS DE RELEVANCIA:
- El fragmento debe hablar directamente del tema de la pregunta.
- Si la pregunta es sobre precios, el fragmento debe tener precios.
- Si la pregunta es sobre exclusiones, el fragmento debe mencionar exclusiones.
- Ignora fragmentos que solo contengan definiciones generales o texto legal sin relaci√≥n directa.

SALIDA ESPERADA:
Devuelve √öNICAMENTE los n√∫meros de los fragmentos relevantes separados por comas (ej: "1, 3, 5").
Si NING√öN fragmento es relevante, devuelve "NINGUNO".`;

    const userPrompt = `PREGUNTA: "${query}"

FRAGMENTOS DISPONIBLES:
${docsText}

¬øCu√°les fragmentos son realmente relevantes?`;

    console.log("ü§ñ Ejecutando Re-ranking con LLM...");
    const response = await rerankLLM.invoke([
        new SystemMessage(systemPrompt),
        new HumanMessage(userPrompt)
    ]);

    const content = response.content.toString().trim();
    console.log(`üéØ Decisi√≥n del Re-ranker: ${content}`);

    if (content.includes("NINGUNO")) {
        return "";
    }

    // Extraer √≠ndices
    const indices = content.match(/\d+/g)?.map(Number) || [];
    
    // Filtrar y unir los documentos seleccionados
    const finalDocs = indices
        .map(i => docs[i - 1]) // Ajustar √≠ndice 1-based a 0-based
        .filter(d => d !== undefined);

    if (finalDocs.length === 0) return "";

    console.log(`‚úÖ Seleccionados ${finalDocs.length} fragmentos finales de alta calidad.`);

    return finalDocs.map(d => d.pageContent).join('\n\n---\n\n');
}
